{"cells":[{"cell_type":"code","metadata":{"cell_id":"0fc92e5e-3aa9-484e-a434-c9054a1c5699"},"source":"!python --version","outputs":[{"name":"stdout","text":"Python 3.7.3\r\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"cell_id":"11ec5d03-c70e-4de5-9473-988d7b8d0ac7"},"source":"# Start writing your code here...","outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"31efbdb2-b21e-42be-b685-479cc2e03caf"},"source":"!ls /datasets/data-export","outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"8ff35b4d-1c5f-4dc6-bfec-17a07e8b848d"},"source":"# imports\nimport json\nfrom collections import MutableMapping, Counter\nfrom pathlib import Path\nfrom itertools import chain","outputs":[{"name":"stderr","text":"/opt/venv/lib/python3.7/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n  This is separate from the ipykernel package so we can avoid doing imports until\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"e414e905-d457-4636-ada8-afc52912a7dc"},"source":"# create directories if not exists\ndef create_directory(path_):\n    path_.mkdir(parents=True, exist_ok=True)\n\n# json reader row by row\ndef json_reader(json_file, line_parser=None, read_many=None):\n    with open(json_file, 'r') as f:\n        lines = f.readlines()[:read_many] if read_many else f.readlines()\n\n        for line in lines:\n            line = line.strip()\n            data = json.loads(line)\n\n            # flatten dictionary\n            if line_parser:\n                data = line_parser(data)\n            yield data\n\ndef convert_flatten(d, parent_key ='', sep ='.'): \n    items = [] \n    for k, v in d.items(): \n        new_key = parent_key + sep + k if parent_key else k \n  \n        if isinstance(v, MutableMapping): \n            items.extend(convert_flatten(v, new_key, sep = sep).items()) \n        else: \n            items.append((new_key, v)) \n    return dict(items)  \n\ndef create_json(data, save_location, new_line=False):\n    with open(save_location, 'w') as outfile:\n        json.dump(data, outfile, sort_keys=True)\n\n        if new_line:\n            outfile.write('\\n')\n\ndef str_to_json(string):\n    j = json.loads(string)\n    return j\n\ndef pretty_json(json_dict):\n    if type(json_dict) == str:\n        json_dict = str_to_json(json_dict)\n    pretty = json.dumps(json_dict, indent=2, sort_keys=True)\n    return pretty","outputs":[]},{"cell_type":"markdown","source":"\n## Only 5 Lines ","metadata":{"tags":[],"cell_id":"2e0e9c0d-64c7-462f-9196-c3d9a1b2231a"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"663a20d2-c2e8-470e-99ef-7d16e88b948e"},"source":"from pathlib import Path\n\ns3_files_loc = Path('/datasets/data-export')\nnew_files_loc = Path('./raw_data2')\n\nfor folder in s3_files_loc.glob('*'):\n    folder_name = folder.name\n\n    save_folder = (new_files_loc / folder_name)\n\n    # make directory\n    create_directory(save_folder)\n\n    # # loop json files in folder\n    for file_ in folder.glob('*.json'):\n        file_name = file_.name\n        save_name = (save_folder / file_name)\n\n        data = {'data': [line for line in json_reader(file_, convert_flatten, 5)]}\n        create_json(data, str(save_name))","outputs":[]},{"cell_type":"markdown","source":"## All Lines","metadata":{"tags":[],"cell_id":"a8d890c8-465d-40c7-8631-bf5b18046091"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"65a2efc0-1480-407e-bf42-1bde9e4593c2"},"source":"from pathlib import Path\n\ns3_files_loc = Path('/datasets/data-export')\nnew_files_loc = Path('./raw_data')\n\nfor folder in s3_files_loc.glob('*'):\n    folder_name = folder.name\n\n    save_folder = (new_files_loc / folder_name)\n\n    # make directory\n    create_directory(save_folder)\n\n    # # loop json files in folder\n    for file_ in folder.glob('*.json'):\n        file_name = file_.name\n        save_name = (save_folder / file_name)\n        \n        data = [line for line in json_reader(file_, convert_flatten)]\n        create_json(data, str(save_name))","outputs":[]},{"cell_type":"markdown","source":"## Testing Raw","metadata":{"tags":[],"cell_id":"f5708716-2570-40ec-93ec-6267243067bd"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"7c80bdda-5a8a-4b3b-ab34-8a402fab8fd0"},"source":"with open('./raw_data/Conversions/part-00000-tid-4871816523311964264-aeb8c126-56be-4c74-a7ce-de3da53de005-716-1-c000.json', 'r') as f:\n    data = json.load(f)\n    print(type(data))","outputs":[{"name":"stdout","text":"<class 'str'>\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"a79409e8-56e6-4114-89c8-4dc79510bd9e"},"source":"df.columns.values","outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"array(['advancePurchaseRangeType', 'browserRequest.browser',\n       'browserRequest.browserFamily', 'browserRequest.deviceFamily',\n       'browserRequest.os', 'browserRequest.osFamily',\n       'browserRequest.referrerUrl', 'browserRequest.screenHeight',\n       'browserRequest.screenPixelDepth', 'browserRequest.screenWidth',\n       'browserRequest.userAgent', 'carDropoffAirportCode',\n       'carPickupAirportCode', 'conversionTransactionType', 'cookieSize',\n       'destination', 'entityId', 'isPublisherConversion',\n       'knownHotelProperty', 'orderId', 'originalConversionCurrency',\n       'origination', 'pageId', 'productCategoryType', 'publisherType',\n       'publisherUserId', 'publisherUserIdPerPub', 'request.buildNumber',\n       'request.requestId', 'request.requestedAt', 'siteId', 'siteType',\n       'thirdPartyCookieAssigned', 'thirdPartyWebuserId', 'travelDateEnd',\n       'travelDateStart', 'travelers', 'tripType', 'rooms'], dtype=object)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Ensure Same Keys Across All","metadata":{"tags":[],"cell_id":"92a27398-f180-46fc-b21d-005a71d5cd72"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"a287f06f-3302-4d03-bc28-a491d0330a4b"},"source":"new_files_loc = Path('./raw_data')\n\n# loop all folders in raw data\n# loop all json files in folder\n# compile all json data (list of dictionaries) into single iterable\n# get all keys from list of dictionaries\n# update all dictionaries to have keys that are missing\n\ndef get_data(file_):\n    with open(file_, 'r') as f:\n        data = json.load(f)\n        return data\n\nfor folder in new_files_loc.glob('*'):\n    # produces generator of list of dictionaries\n    all_json_data = (get_data(file_) for file_ in folder.glob('*.json'))\n\n    # create single list of all dictionarys (rows) from all json files\n    flattened = chain.from_iterable(all_json_data)\n\n    # all keys for folder type\n    all_keys = set(chain.from_iterable(flattened))\n\n    # loop through dictionaries and update with missing keys\n\n    # create json\n    create_json(data, f'./dataframes/{folder.name}.json')\n    ","outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-900e16879e27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# all keys for folder type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mall_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflattened\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# loop through dictionaries and update with missing keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-900e16879e27>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_files_loc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mall_json_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfolder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'*.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mflattened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_json_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-900e16879e27>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(file_)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0mkwarg\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mJSONDecoder\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \"\"\"\n\u001b[0;32m--> 293\u001b[0;31m     return loads(fp.read(),\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/venv/lib/python3.7/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"7b897801-594d-471b-ad63-6f8b3fe164f7"},"source":"file_ = './raw_data/Conversions/part-00000-tid-4871816523311964264-aeb8c126-56be-4c74-a7ce-de3da53de005-716-1-c000.json'\n\nwith open(file_, 'r') as f:\n    data = json.load(f)\n    test = set(chain.from_iterable(data))\n    for t in test:\n        print(t)","outputs":[{"name":"stdout","text":"travelDateEnd\nrequest.requestId\norderId\nisPublisherConversion\ncookieSize\npublisherType\nthirdPartyCookieAssigned\nbrowserRequest.browserFamily\nthirdPartyWebuserId\nentityId\nbrowserRequest.userAgent\nbrowserRequest.os\npublisherUserIdPerPub\nbrowserRequest.screenPixelDepth\nbrowserRequest.screenWidth\nbrowserRequest.deviceFamily\nrequest.requestedAt\ntravelDateStart\npageId\nbrowserRequest.osFamily\nbrowserRequest.browser\nadvancePurchaseRangeType\nrequest.buildNumber\nbrowserRequest.referrerUrl\ntravelers\nsiteId\noriginalConversionCurrency\ntripType\nconversionTransactionType\norigination\nrooms\nbrowserRequest.screenHeight\nknownHotelProperty\ncarPickupAirportCode\nproductCategoryType\nsiteType\ndestination\ncarDropoffAirportCode\npublisherUserId\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"16469b7d-c1f2-498a-99ad-be662f794872"},"source":"new_files_loc = Path('./raw_data')\n\ndef get_data(file_):\n    with open(file_, 'r') as f:\n        data = json.load(f)\n        return data\n\ndef update_dic(dic, full_key_list):\n    for k in (full_key_list - dic.keys()):\n        dic[k] = None\n    return dic\n\nfor folder in new_files_loc.glob('*'):\n    # produces generator of list of dictionaries\n    all_json_data = (get_data(file_) for file_ in folder.glob('*.json'))\n\n    # create single list of all dictionarys (rows) from all json files\n    flattened = chain.from_iterable(all_json_data)\n\n    # get all of the keys from flattened\n    all_keys = set(chain.from_iterable(flattened))\n\n    # update dictionaries with missing keys\n    updated_flattened = (update_dic(dic, all_keys) for dic in flattened)\n    \n    # loop json lines and create json\n    for line in updated_flattened:\n        print(line)\n        # create_json(line, f'./dataframes/{folder.name}.json', True)\n  ","outputs":[]}],"nbformat":4,"nbformat_minor":2,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"},"deepnote_notebook_id":"3df83f6a-c0c1-47bb-bfe7-b6d7b4365851","deepnote_execution_queue":[]}}